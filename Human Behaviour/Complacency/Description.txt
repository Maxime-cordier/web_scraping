Critics of the use of the term “complacency” often refer to the lack of its precise definition. It is a topic which has not yet been adequately conceptualized and any use of the term contributes to an illusion of understanding of what causes risks. The use and definition of complacency is referred to in Folk Modelling. Folk models share the following characteristics: Critics often also refer to the variety of “substitution” definitions in the literature, where one label is used instead of complacency. Here is what a good sample of the literature has equated complacency with: For example, self-satisfaction takes the place of complacency and is assumed to speak for itself. Looking for “self-satisfaction” in a controller’s behaviour is not any better or more convincing than looking for “complacency”. There is no explanation (or breakdown) of a psychological mechanism that makes self-satisfaction emerge, and which in turn produces a lack of Vigilance in ATM. It can be argued that if the literature can’t provide ways in which you can start to define and identify the phenomenon in question, then it is easy to argue for its existence in real situations. To be complacent, some argue, an observer must be shown to sample a variable less often than is optimal, given the dynamics of what is going on in the system at that time. But it is very difficult to rigorously define the optimal sampling rate in supervisory monitoring. This can also be tested against particular situation in ATC. Another criticism is that we cannot claim that somebody was complacent because he or she missed a piece of data (that we, in hindsight, find important). Complacency, after all, is about under-sampling or defective monitoring (which is impossible to establish because you can’t define the optimal). It is not about whether people detected signals. Detectability is a function of signal-to-noise ratio and somebody’s response criterion (as in, when do I have enough evidence to do something), not of sampling strategy.