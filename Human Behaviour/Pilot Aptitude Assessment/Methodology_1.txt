In general terms, the hiring process at most companies consists of: Establishing requirements. Posting job advertisement. Screening and selection of applicants. Interview/aptitude testing of selected candidates. Evaluation of test and interview results. Hiring decision. Of these steps, screening, interview/aptitude testing, and test evaluation are the most critical to overall success. A well-structured screening, testing and evaluation process will play a key role in the success of the recruitment process and in determining the quality of the staff hired. However, before commencing these processes, it is essential that there is a clear definition of the job requirement profile. This profile is based on a job analysis and identifies the dimensions. commonly called KSAs (knowledge, skills and attitudes) and personality traits, required to perform the job within the company context. Screening is often used at the beginning of the hiring process to eliminate those candidates who send applications without meeting the predefined requirements. However, care should be taken to not be overly stringent at this stage in order to avoid the premature exclusion of suitable candidates. Screening can also be used to identify the best among a group of qualified applicants. Screening tools include: review of applicant CVs. contact of references. questionnaires. screening interviews.. According to IATA, a complete battery of aptitude tests will consist of at least: Tests of basic mental abilities. Tests of operational competencies. Tests of social competencies. Interviews to capture relevant personality traits. Testing can be accomplished using any or all of: paper-pencil tests. computer based tests. psychometric apparatus tests. computer based psychometric tests. simulator based tests. group scenarios. interviews. Using the results of aptitude testing to reliably predict the future performance of pilots is dependent upon a number of factors. These include: Test reliability - the accuracy and consistency of the measurement characteristic of a given test is called reliability. When interpreting test scores, it is necessary to know how well they differentiate the given levels of abilities of various candidates. Test validity - the validity of a test expresses the extent to which it actually measures what it has been designed to measure. Norm - A raw score is meaningless unless there is a "norm" to which it can be compared. Comparing the candidate’s performance with the norm allows determination of how far the candidate’s performance is above or below the performance of the comparison group. Measurement scales - A pass/fail designation holds little value in the context of aptitude assessment. Conversely, scales are useful for expressing the results of performance measurements in a numeric way. A minimum of three, fixed interval, possible scores are required while four or more possible scores provide greater discrimination. A scale such as unsatisfactory/low average/average/superior/outstanding, with an appropriate numerical equivalency, could be used to express test results in a meaningful way.. Where the testing is subjective, that is the scoring is based on the judgement of the evaluator, it is critical that evaluators are trained appropriately and that inter evaluator scoring is consistent. In other words, all evaluators should assign